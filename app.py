# app.py (ìµœì¢… ì™„ì„± ë²„ì „)
import streamlit as st
from google.oauth2 import service_account
from google.cloud import firestore
from datetime import datetime

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document

# --- Firestore ì¸ì¦ ì •ë³´ ì„¤ì • ---
# ì´ ë¶€ë¶„ì€ Streamlit Cloudì˜ Secrets ì„¤ì •ì„ í†µí•´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
try:
    creds_dict = {
        "type": st.secrets.firestore.type,
        "project_id": st.secrets.firestore.project_id,
        "private_key_id": st.secrets.firestore.private_key_id,
        "private_key": st.secrets.firestore.private_key.replace('\\n', '\n'),
        "client_email": st.secrets.firestore.client_email,
        "client_id": st.secrets.firestore.client_id,
        "auth_uri": st.secrets.firestore.auth_uri,
        "token_uri": st.secrets.firestore.token_uri,
        "auth_provider_x509_cert_url": st.secrets.firestore.auth_provider_x509_cert_url,
        "client_x509_cert_url": st.secrets.firestore.client_x509_cert_url
    }
    creds = service_account.Credentials.from_service_account_info(creds_dict)
    db = firestore.Client(credentials=creds)

except Exception as e:
    st.error("âš ï¸ Firestore ì¸ì¦ ì •ë³´ ì„¤ì •ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.error(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
    st.stop()

# --- ì´í•˜ ì±—ë´‡ ë¡œì§ (ì´ì „ê³¼ ë™ì¼) ---
def load_documents_from_firestore():
    docs_ref = db.collection('documents').stream()
    documents_list = [Document(page_content=doc.to_dict().get('content', ''), metadata={'source': doc.to_dict().get('source', '')}) for doc in docs_ref]
    return documents_list

@st.cache_resource(ttl="10m")
def setup_rag_pipeline_from_db():
    with st.spinner("ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        docs = load_documents_from_firestore()

    if not docs:
        st.error("Firestoreì—ì„œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_documents = text_splitter.split_documents(docs)
    embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    vector_db = FAISS.from_documents(documents=split_documents, embedding=embedding_model)
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=st.secrets["GOOGLE_API_KEY"])

    prompt = ChatPromptTemplate.from_template("Context:\n{context}\n\nQuestion: {input}\n\nAnswer:")
    document_chain = create_stuff_documents_chain(llm, prompt)
    retriever = vector_db.as_retriever()
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    return retrieval_chain, datetime.now()

# --- Streamlit UI ì„¤ì • ---
st.title("ğŸ“œ ì œë¯¸ë‹ˆ AI ì—°êµ¬ì†Œ ê·œì • ì•ˆë‚´ ì±—ë´‡")
st.markdown("---")

try:
    retrieval_chain, cached_time = setup_rag_pipeline_from_db()
    st.success(f"ì§€ì‹ DBê°€ {cached_time.strftime('%Hì‹œ %Më¶„ %Sì´ˆ')}ì— ì—…ë°ì´íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤.")

    user_query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_query")

    if user_query:
        with st.spinner("Geminiê°€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            response = retrieval_chain.invoke({"input": user_query})
            st.markdown("#### ë‹µë³€:")
            st.write(response["answer"])

except Exception as e:
    st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")