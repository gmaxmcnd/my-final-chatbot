# multimodal_rag_app.py (AttributeError í•´ê²°ëœ ìµœì¢… ë²„ì „)
import streamlit as st
import os
import base64
import mimetypes
from langchain_google_vertexai import VertexAIEmbeddings, ChatVertexAI
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage
from PIL import Image

# --- ì„¤ì • ---
FAISS_INDEX_PATH = "faiss_multimodal_index"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "firestore-key.json"

# --- í—¬í¼ í•¨ìˆ˜: ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜ ---
def image_to_base64_uri(file_path_or_bytes):
    """ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë‚˜ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ Base64 ë°ì´í„° URIë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° ë°”ì´íŠ¸ë¡œ ì½ê¸°
    if isinstance(file_path_or_bytes, str):
        mime_type, _ = mimetypes.guess_type(file_path_or_bytes)
        if mime_type is None:
            mime_type = 'image/jpeg'
        with open(file_path_or_bytes, "rb") as image_file:
            bytes_data = image_file.read()
    # ë°”ì´íŠ¸ ë°ì´í„°ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš© (UploadedFile ì²˜ë¦¬)
    else:
        # Streamlit UploadedFileì€ .type ì†ì„±ì„ ê°€ì§
        mime_type = file_path_or_bytes.type
        bytes_data = file_path_or_bytes.getvalue()

    encoded_string = base64.b64encode(bytes_data).decode("utf-8")
    return f"data:{mime_type};base64,{encoded_string}"

# --- í•µì‹¬ í•¨ìˆ˜ ---
@st.cache_resource
def load_retriever():
    """ë¡œì»¬ì— ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ì—¬ retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    embedding_model = VertexAIEmbeddings(model_name="multimodalembedding@001")
    vector_store = FAISS.load_local(FAISS_INDEX_PATH, embedding_model, allow_dangerous_deserialization=True)
    return vector_store.as_retriever(search_kwargs={"k": 3})

def get_answer_from_llm(retriever, query_text=None, query_image=None):
    """í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ RAGë¥¼ ìˆ˜í–‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # 1. ì¿¼ë¦¬ ì„ë² ë”©ì„ ìœ„í•œ ì…ë ¥ êµ¬ì„±
    retrieval_input = query_text if query_text else Image.open(query_image)

    # 2. RAG ìˆ˜í–‰: ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    relevant_docs = retriever.invoke(retrieval_input)

    # 3. LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_content = []
    st.write("---")
    st.markdown("#### ğŸ“š ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´ (Context):")
    for doc in relevant_docs:
        if doc.metadata['type'] == 'text':
            context_content.append({"type": "text", "text": f"ì°¸ê³  í…ìŠ¤íŠ¸: {doc.page_content}"})
            st.text(f"[í…ìŠ¤íŠ¸] {doc.metadata['source']}")
        elif doc.metadata['type'] == 'image':
            image_uri = image_to_base64_uri(doc.metadata['path'])
            context_content.append({"type": "image_url", "image_url": {"url": image_uri}})
            st.image(doc.metadata['path'], caption=f"[ì´ë¯¸ì§€] {doc.metadata['source']}", width=200)

    # 4. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_text = "ë‹¹ì‹ ì€ ì œë¯¸ë‹ˆ AI ì—°êµ¬ì†Œì˜ ê·œì • ì•ˆë‚´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ 'ê´€ë ¨ ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ 'ì§ˆë¬¸'ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."

    user_original_query = [{"type": "text", "text": "--- ì§ˆë¬¸ ---"}]
    if query_text:
        user_original_query.append({"type": "text", "text": query_text})
    if query_image:
        image_uri = image_to_base64_uri(query_image)
        user_original_query.append({"type": "image_url", "image_url": {"url": image_uri}})

    final_prompt_content = [
        {"type": "text", "text": prompt_text},
        {"type": "text", "text": "--- ê´€ë ¨ ì •ë³´ ---"},
        *context_content,
        *user_original_query
    ]

    # 5. LLM í˜¸ì¶œ
    llm = ChatVertexAI(model_name="gemini-1.0-pro-vision", location="asia-northeast3")
    message = HumanMessage(content=final_prompt_content)
    response = llm.invoke([message])
    return response.content

# --- Streamlit UI ---
st.set_page_config(page_title="ë©€í‹°ëª¨ë‹¬ RAG ì±—ë´‡", page_icon="ğŸ§ ")
st.title("ğŸ§  ë©€í‹°ëª¨ë‹¬ RAG ì±—ë´‡")
st.markdown("í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ì†Œ ê·œì •ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

try:
    retriever = load_retriever()

    query_text = st.text_input("í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ê¸°:")
    query_image = st.file_uploader("ì´ë¯¸ì§€ë¡œ ì§ˆë¬¸í•˜ê¸°:", type=["jpg", "jpeg", "png"])

    if st.button("ë‹µë³€ ìƒì„±"):
        if not query_text and not query_image:
            st.warning("í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ê³  Geminiê°€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                if query_image:
                    st.image(query_image, caption="ì§ˆë¬¸ ì´ë¯¸ì§€")
                answer = get_answer_from_llm(retriever, query_text, query_image)
                st.markdown("---")
                st.markdown("#### âœ¨ ìµœì¢… ë‹µë³€:")
                st.markdown(answer)

except FileNotFoundError:
    st.error(f"'{FAISS_INDEX_PATH}' ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `indexer.py`ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
except Exception as e:
    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")